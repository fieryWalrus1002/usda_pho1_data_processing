{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to extract and combine the data and create a unified time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (3372038876.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    This code snippet is designed to clear out existing data and plots in specific directories. Here's a breakdown of what it does:\u001b[0m\n\u001b[1;37m                                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "This code snippet is designed to clear out existing data and plots in specific directories. Here's a breakdown of what it does:\n",
    "# # clear out the existing data and plots\n",
    "# import os\n",
    "\n",
    "# base_dir = os.path.dirname(os.path.realpath('./protocols/04032024_usda_rice'))\n",
    "# dirs = ['output_data', 'output_plots', 'output_protocol', 'scripts']\n",
    "# for d in dirs:\n",
    "#     if os.path.exists(d):\n",
    "#         for f in os.listdir(d):\n",
    "#             os.remove(os.path.join(d, f))\n",
    "#     else:\n",
    "#         os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries, and defines LED names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytz pandas numpy seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "# for the date and time, parsing from json metadata into a filename for export\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd  # for dataframes, data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np  # for linear algebra, arrays, operations on numerical tables and matrices\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import seaborn as sns  # for making plots with seaborn\n",
    "\n",
    "# dict for translating the light number to a string\n",
    "light_dict = {\n",
    "    0: \"dark\",\n",
    "    1: \"530nm\",\n",
    "    2: \"655nm\",\n",
    "    3: \"590nm\",\n",
    "    4: \"448nm\",\n",
    "    5: \"950nm\",\n",
    "    6: \"950nm\",\n",
    "    7: \"655nm\",\n",
    "    8: \"850nm\",\n",
    "    9: \"730nm\",\n",
    "    10: \"820nm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_name(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Take an experiment datafile and parse the experiment name from the file metadata\n",
    "    into a string in the form of:\n",
    "    '%Y%M%D_experiment_name'\n",
    "    If experiment = testMacro, name = 012424_leaf_fr150_fr0SP, and created_at = 2024-01-25T00:58:36.782Z\n",
    "    then the function should return:\n",
    "    '20240125_testMacro_012424_leaf_fr150_fr0SP'\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename) as file:\n",
    "        obj = json.load(file)[0]\n",
    "\n",
    "    experiment = obj[\"experiment\"]\n",
    "    name = re.sub(r\"\\d{6}(_)+\", \"\", obj[\"name\"])\n",
    "    created_at = obj[\"created_at\"]\n",
    "\n",
    "    # Convert the timestamp to datetime object\n",
    "    dt = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    # Set the timezone to UTC\n",
    "    dt = dt.replace(tzinfo=pytz.UTC)\n",
    "\n",
    "    # Convert the datetime object to PST\n",
    "    dt_pst = dt.astimezone(pytz.timezone(\"US/Pacific\"))\n",
    "\n",
    "    # Format the datetime object as a string\n",
    "    created_at_pst = dt_pst.strftime(\"%Y%m%d\")\n",
    "\n",
    "    print(f\"experiment: {experiment}, name: {name}, created_at: {created_at_pst}\")\n",
    "\n",
    "    return created_at_pst + \"_\" + experiment + \"_\" + name\n",
    "\n",
    "\n",
    "#### parse the varray into a dict for reference, with the various codes of the varray reference\n",
    "### returning the values they represent when we query the varray.\n",
    "### Eg varray[\"@n4:0\"] = \"820nm\"\n",
    "def parse_varray(vArrayDict) -> Dict:\n",
    "    \"\"\"dict, extract the parts we need and parse them into a dict for reference\"\"\"\n",
    "    parsed = {}\n",
    "    for i in range(len(vArrayDict)):\n",
    "        for j in range(len(vArrayDict[i])):\n",
    "            parsed[f\"@n{i}:{j}\"] = vArrayDict[i][j]\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def get_data_from_file(file_path: str) -> Dict:\n",
    "    print(f\"Attempting to load data from : {file_path}\")\n",
    "    with open(filename) as file:\n",
    "        root = json.load(file)\n",
    "\n",
    "    ########################## get the data set ###############################\n",
    "    # does the data_set exist? check to see if it is nested in data, or just exposed as sample\n",
    "    try:\n",
    "        data_set = root[0][\"data\"][\"sample\"][0][\"set\"]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            data_set = root[0][\"sample\"][0][\"set\"]\n",
    "        except KeyError:\n",
    "            data_set = \"blank\"\n",
    "\n",
    "    if data_set == \"blank\":\n",
    "        print(\"no data set found\")\n",
    "    else:\n",
    "        print(\"Data found, returning data_set with length: \", len(data_set))\n",
    "\n",
    "    # sort data_set by time\n",
    "    data_set = sorted(data_set, key=lambda k: k[\"time\"])\n",
    "\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def get_protocol_from_file(file_path: str) -> Dict:\n",
    "    print(f\"Attempting to load protocol from : {file_path}\")\n",
    "    with open(file_path) as file:\n",
    "        root = json.load(file)\n",
    "\n",
    "    protocolStr = root[0][\"protocol\"]\n",
    "\n",
    "    try:\n",
    "        # parse the json string into a dict\n",
    "        protocol_dict = json.loads(protocolStr)[0]\n",
    "    except TypeError:\n",
    "        print(\"protocol is not a string, skipping\")\n",
    "\n",
    "    return protocol_dict\n",
    "\n",
    "\n",
    "def parse_vlist(vlist: List[str], varray: dict) -> List[int]:\n",
    "    parsed = []\n",
    "    for item in vlist:\n",
    "        if type(item) != str:\n",
    "            parsed.append(int(item))\n",
    "        else:\n",
    "            parsed.append(int(varray[item]))\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def getProtocolForLabel(label: str, protocols: dict) -> dict:\n",
    "    protocolList = protocols[\"_protocol_set_\"]\n",
    "    for protocol in protocolList:\n",
    "        if protocol[\"label\"] == label:\n",
    "            return protocol\n",
    "    return None\n",
    "\n",
    "\n",
    "# extract all of the start times for each trace in the protocol script, and calculate\n",
    "# the time in milliseconds from the beginning of the experiment\n",
    "# This allows us to create an accurate time series for the data\n",
    "def get_experiment_start_times_ms(filename: str) -> dict:\n",
    "    with open(filename) as file:\n",
    "        root = json.load(file)[0]\n",
    "\n",
    "    # The object may be nested in a \"data\" object, or just exposed as \"sample\"\n",
    "    try:\n",
    "        data = root[\"data\"]\n",
    "    except KeyError:\n",
    "        data = root\n",
    "\n",
    "    experiment_start_time = int(data[\"time\"])\n",
    "    time_dict = {\"experiment_start\": experiment_start_time}\n",
    "    time_list = []\n",
    "\n",
    "    for i, protocol in enumerate(data[\"sample\"][0][\"set\"]):\n",
    "        time_list.append(\n",
    "            {\n",
    "                \"label\": protocol[\"label\"],\n",
    "                \"time_ms\": (int(protocol[\"time\"]) - experiment_start_time),  # in ms\n",
    "            }\n",
    "        )\n",
    "\n",
    "    time_dict[\"protocol_times\"] = time_list\n",
    "    return time_dict\n",
    "\n",
    "\n",
    "def convert_epoch_ms_to_datetime(epoch: int) -> datetime:\n",
    "    return datetime.fromtimestamp(epoch / 1000.0)\n",
    "\n",
    "    # create a time axis, using the protocol of the experiment. Values for pulse distance are\n",
    "\n",
    "\n",
    "# in microseconds, so we need to convert them to milliseconds\n",
    "def create_time_axis(label: str, iter: int, experiment_dict: dict) -> list:\n",
    "    time_axis = []\n",
    "    protocol_times = experiment_dict[\"time_dict\"][\"protocol_times\"]\n",
    "    protocolScript = getProtocolForLabel(label, experiment_dict[\"protocols\"])\n",
    "    print(f\"protocolScript: {protocolScript}\")\n",
    "\n",
    "    if protocol_times[iter][\"label\"] != label:\n",
    "        print(f\"label mismatch: {protocol_times[iter]['label']} != {label}\")\n",
    "        return None\n",
    "    print(f\"protocol_times: {protocol_times}\")\n",
    "\n",
    "    pulses = parse_vlist(protocolScript[\"pulses\"], experiment_dict[\"varray\"])\n",
    "    print(f\"pulses: {pulses}\")\n",
    "\n",
    "    pulse_distance_us = parse_vlist(\n",
    "        protocolScript[\"pulse_distance\"], experiment_dict[\"varray\"]\n",
    "    )\n",
    "    print(f\"pulse_distance_us: {pulse_distance_us}\")\n",
    "\n",
    "    pulse_distance_ms = [x / 1000 for x in pulse_distance_us]\n",
    "    print(f\"pulse_distance_ms: {pulse_distance_ms}\")\n",
    "\n",
    "    trace_start_ms = protocol_times[iter][\"time_ms\"]\n",
    "    print(f\"trace_start_ms: {trace_start_ms}\")\n",
    "\n",
    "    # i for each unit of pulses, [500, 500, 500] for a 1500 pulse experiment\n",
    "    # Each unit of pulses has a corresponding pulse_distance [1000, 1000, 1000] would be 1 ms pulse distance\n",
    "    # We converted the us pulse distance to ms above, so we don't have to do it here\n",
    "    last_time_point = trace_start_ms\n",
    "    for i in range(len(pulses)):\n",
    "        # j for each pulse in the range i of pulses, ex 0:500 for the first 500 pulses\n",
    "        for j in range(pulses[i]):\n",
    "            current_time_point = round(last_time_point + pulse_distance_ms[i], 4)\n",
    "            time_axis.append(current_time_point)\n",
    "            last_time_point = current_time_point\n",
    "\n",
    "    print(f\"time_axis: {time_axis}\")\n",
    "\n",
    "    if len(time_axis) != sum(pulses):\n",
    "        print(f\"length of time axis: {len(time_axis)} != sum of pulses: {sum(pulses)}\")\n",
    "        return None\n",
    "\n",
    "    return time_axis\n",
    "\n",
    "\n",
    "def deinterpolate_data(data: list, protocol: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Takes in a list of data and a protocol dict, and then deinterpolates it into a list of lists, where each list\n",
    "    is a trace of data from a single light source. Then concatenates the lists into a single list\n",
    "    of values, and returns it in a dict along with the lednums so you can tell which light source the data came from.\n",
    "    \"\"\"\n",
    "    pulsed_lights = protocol.get(\"pulsed_lights\", 0)\n",
    "    pulse_phases = protocol.get(\"pulses\", 0)\n",
    "\n",
    "    # exit early if there are no pulsed lights or pulse phases\n",
    "    if pulsed_lights == 0 or pulse_phases == 0:\n",
    "        return None\n",
    "\n",
    "    num_pulsed_leds = len(pulsed_lights[0])\n",
    "\n",
    "    # exit early if there is only one light, no need to deinterpolate\n",
    "    print(f\"num_pulsed_leds: {num_pulsed_leds}\")\n",
    "    if num_pulsed_leds == 1:\n",
    "        lednums = [pulsed_lights[0][0] for i in range(len(data))]\n",
    "        return {\"values\": data, \"lednums\": lednums}\n",
    "\n",
    "    total_pulses = num_pulsed_leds * sum(pulse_phases)\n",
    "\n",
    "    print(f\"num_pulsed_leds: {num_pulsed_leds}, total_pulses: {total_pulses}\")\n",
    "\n",
    "    # so now we can verify that our number is equal to the length of the data list\n",
    "    if total_pulses != len(data):\n",
    "        print(f\"total_pulses: {total_pulses} != len(data): {len(data)}\")\n",
    "        return None\n",
    "\n",
    "    # if the number of pulses is equal to the length of the data list, then we can\n",
    "    # deinterpolate the data into a list of lists, where each list is a trace of data\n",
    "    # from a single light source\n",
    "    deinterpolated_data = [[] for i in range(num_pulsed_leds)]\n",
    "    print(\n",
    "        f\"deinterpolated_data: {len(deinterpolated_data)}, num_pulsed_leds: {num_pulsed_leds}\"\n",
    "    )\n",
    "\n",
    "    for i in range(total_pulses):\n",
    "        # the order of the points is repeated, like: 0, 1, 0, 1, 0, 1, 0, 1, 0, 1\n",
    "        # so if i is 0, 2, 4, 6, 8, then we append that datapoint to the first list\n",
    "        # if i is 1, 3, 5, 7, 9, then we append that datapoint to the second list\n",
    "        if num_pulsed_leds == 1:\n",
    "            deinterpolated_data[0].append(data[i])\n",
    "            continue\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            deinterpolated_data[0].append(data[i])\n",
    "        else:\n",
    "            deinterpolated_data[1].append(data[i])\n",
    "\n",
    "    print(\n",
    "        f\"len(deinterpolated_data[0]): {len(deinterpolated_data[0])}, len(deinterpolated_data[1]): {len(deinterpolated_data[1])}\"\n",
    "    )\n",
    "\n",
    "    # The length of each of those lists should be equal to the total_pulses / num_pulsed_leds\n",
    "    if len(deinterpolated_data[0]) != total_pulses / num_pulsed_leds:\n",
    "        print(\n",
    "            f\"len(deinterpolated_data[0]): {len(deinterpolated_data[0])} != total_pulses / num_pulsed_leds: {total_pulses / num_pulsed_leds}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    # concatenate the lists into a single list of values, with the first list first, and the second list second\n",
    "    concatenated_data = deinterpolated_data[0] + deinterpolated_data[1]\n",
    "\n",
    "    print(f\"len(concatenated_data): {len(concatenated_data)}\")\n",
    "\n",
    "    concatenated_lednums = [pulsed_lights[0][0] for i in deinterpolated_data[0]] + [\n",
    "        pulsed_lights[0][1] for i in deinterpolated_data[1]\n",
    "    ]\n",
    "\n",
    "    # return a dict of the concatenated data and the concatenated lednums\n",
    "    return {\"values\": concatenated_data, \"lednums\": concatenated_lednums}\n",
    "\n",
    "\n",
    "def convert_led_nums_to_wavelength(lednums: list) -> list:\n",
    "    return [light_dict[i] for i in lednums]\n",
    "\n",
    "\n",
    "def create_df(iter: int, data: dict, experiment_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function will take in a data dict, and then figure out if it is a single trace or a multi-trace\n",
    "    experiment. It will then create a pandas dataframe from the data, and return it.\n",
    "\n",
    "    The \"data_raw\" will need to be split into its individual parts, and then a time axis will be created\n",
    "    that can be applied to both parts.\n",
    "\n",
    "    There will be a shared time axis and value column, with each trace having a wavelength column that lists\n",
    "    the measuring light used was.\n",
    "\n",
    "    params:\n",
    "    iter: int, the index of the protocol in the experiment_dic\n",
    "    data: dict, the data from the experiment\n",
    "    experiment_dict: dict, the dict containing the experiment data parameters, like the protocols, varray, etc.\n",
    "\n",
    "    returns:\n",
    "    pd.DataFrame, a dataframe of the data from the experiment like: labels, time_ms, wavelength, value, experiment_name, trace_num\n",
    "    \"\"\"\n",
    "    print(f\"creating dataframe for {data['label']}, trace {iter}\")\n",
    "    protocolScript = getProtocolForLabel(d[\"label\"], experiment_dict[\"protocols\"])\n",
    "\n",
    "    data_raw = deinterpolate_data(data[\"data_raw\"], protocolScript)\n",
    "\n",
    "    if data_raw == None:\n",
    "        print(f\"deinterpolate_data returned None for {d['label']}, trace {i}\")\n",
    "        return None\n",
    "\n",
    "    values = data_raw[\"values\"]\n",
    "\n",
    "    wavelength = convert_led_nums_to_wavelength(data_raw[\"lednums\"])\n",
    "\n",
    "    labels = [d[\"label\"] for j in range(len(values))]\n",
    "\n",
    "    time_ms = create_time_axis(d[\"label\"], iter, experiment_dict)\n",
    "\n",
    "    trace_num = [i for j in range(len(d[\"data_raw\"]))]\n",
    "\n",
    "    print(f\"creating dataframe for {d['label']}, trace {iter}\")\n",
    "\n",
    "    print(\n",
    "        f\"len(values): {len(values)}, len(labels): {len(labels)}, len(time_ms): {len(time_ms)}\"\n",
    "    )\n",
    "\n",
    "    if len(time_ms) != len(values):\n",
    "        time_ms = time_ms + time_ms\n",
    "\n",
    "    print(len(time_ms), len(values))\n",
    "\n",
    "    # adjust the time_ms to start at 0\n",
    "    trace_start = min(time_ms)\n",
    "    time_ms_trace = [t - trace_start for t in time_ms]\n",
    "\n",
    "    data_dict = {\n",
    "        \"labels\": labels,\n",
    "        \"time_ms\": time_ms,\n",
    "        \"time_ms_trace\": time_ms_trace,\n",
    "        \"wavelength\": wavelength,\n",
    "        \"value\": values,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"trace_num\": trace_num,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "def get_true_zero(df: pd.DataFrame) -> int:\n",
    "    # get the mean of the values in which the labels fields includes \"trueZero\"\n",
    "    # trueZero_noSP_noML_noActinic\n",
    "    trueZero = df[p700_df[\"labels\"].str.contains(\"trueZero\")][\"value\"].mean()\n",
    "    print(f\"trueZero: {trueZero}\")\n",
    "    return trueZero\n",
    "\n",
    "\n",
    "def calculate_fvfm(df: pd.DataFrame, true_zero: int) -> float:\n",
    "    # Calculate Fv/Fm\n",
    "    # Fv = Fm - Fo\n",
    "    # Fm = max fluorescence\n",
    "    # Fo = minimal fluorescence\n",
    "    # Fv/Fm = (Fm - Fo) / Fm    # Fo is the minimal fluorescence measured in the dark-adapted state\n",
    "\n",
    "    # subtract the offset from true zero, and calculate the mean of the values\n",
    "\n",
    "    Fo = df.iloc[25:30][\"value\"].mean() - true_zero\n",
    "    Fm = df.iloc[40:50][\"value\"].mean() - true_zero\n",
    "\n",
    "    print(f\"Fo: {Fo}, Fm: {Fm}\")\n",
    "\n",
    "    return round((Fm - Fo) / Fm, 2)  # two decimal places is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and protocol details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob(\"data/*.json\")\n",
    "\n",
    "files = [filename for filename in files if \"4193\" in filename]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number =\n",
    "\n",
    "with open(filename) as file:\n",
    "\n",
    "    root = json.load(file)[0]\n",
    "\n",
    "print(f\"Filename: {filename}\")\n",
    "# whats the current status of this ovject? any keys?\n",
    "print(root.keys())\n",
    "\n",
    "\n",
    "time_dict = get_experiment_start_times_ms(filename)\n",
    "print(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the data from the file and parse it into a dict, or return \"blank\"\n",
    "time_dict = get_experiment_start_times_ms(filename)\n",
    "start = time_dict[\"experiment_start\"]\n",
    "data_set = get_data_from_file(filename)\n",
    "protocol_dict = get_protocol_from_file(filename)\n",
    "experiment_name = get_experiment_name(filename)\n",
    "try:\n",
    "    varray = parse_varray(protocol_dict[\"v_arrays\"])\n",
    "except KeyError:\n",
    "    print(\"no varray found\")\n",
    "    varray = None\n",
    "\n",
    "# create a dict to hold all the experiment data and parameters\n",
    "experiment_dict = {\n",
    "    \"data_set\": data_set,\n",
    "    \"protocols\": protocol_dict,\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"experiment_date\": experiment_name[:8],\n",
    "    \"experiment\": experiment_name[9:],\n",
    "    \"varray\": varray,\n",
    "    \"start_time\": start,\n",
    "    \"time_dict\": time_dict,\n",
    "    \"true_zero\": -156\n",
    "}\n",
    "print(experiment_dict[\"time_dict\"])\n",
    "print(experiment_name)\n",
    "print(experiment_dict[\"protocols\"])\n",
    "print(experiment_dict[\"experiment\"])\n",
    "print(experiment_dict[\"experiment_date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data and create the unified time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i, d in enumerate(data_set):\n",
    "    d_df = create_df(i, d, experiment_dict)\n",
    "    if d_df is None:\n",
    "        print(f\"create_df returned None for {d['label']}, trace {i}\")\n",
    "        continue\n",
    "\n",
    "    # check to see that the time_axis is a sequential list of numbers\n",
    "    if (np.diff(d_df[\"time_ms\"]) > 0).all():\n",
    "        print(\"time axis is sequential\")\n",
    "    else:\n",
    "        print(\"time axis is not sequential\")\n",
    "\n",
    "    print(d_df.head())\n",
    "\n",
    "    # concatenate the dataframes\n",
    "    df = pd.concat([df, pd.DataFrame(d_df)], ignore_index=True)\n",
    "\n",
    "df[\"time_s\"] = round(df[\"time_ms\"] / 1000, 6)\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "# adjust for true zero, at -156\n",
    "df[\"value\"] = df[\"value\"].apply(lambda x: x - experiment_dict[\"true_zero\"])\n",
    "\n",
    "\n",
    "# remove all the \"Preillum\" labels, we don't need them\n",
    "df = df[~df[\"labels\"].str.contains(\"Preillum\")]\n",
    "\n",
    "\n",
    "# save the data to disk\n",
    "df.to_csv(f\"output_data/{experiment_name}.csv\")\n",
    "\n",
    "# export the protocol to a json file\n",
    "with open(f\"output_protocol/{experiment_name}_protocol.json\", \"w\") as file:\n",
    "    json.dump(protocol_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # okay, so we can parse the labels into a dict, and then use that to create new columns in the dataframe\n",
    "# # for each of the values in the dict\n",
    "# def parse_label_to_variables_dict(label: str) -> dict:\n",
    "#     label = label.split(\"_\")\n",
    "#     return {label[i]: label[i + 1] for i in range(0, len(label), 2)}\n",
    "\n",
    "# # test it out\n",
    "# df = pd.read_csv(f\"output_data/{experiment_name}.csv\")\n",
    "\n",
    "# # now create columns for each of the values in the dict\n",
    "# df = pd.concat([df, df[\"labels\"].apply(parse_label_to_variables_dict).apply(pd.Series)], axis=1)\n",
    "\n",
    "# # rename the wl column to \"target_wl\"\n",
    "# df.rename(columns={\"wl\": \"target_wl\"}, inplace=True)\n",
    "\n",
    "# print(df.head())\n",
    "# df.to_csv(f\"output_data/{experiment_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(f\"output_data/{experiment_name}.csv\")\n",
    "\n",
    "print(f\"data.columns= {data.columns}\")\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Identify unique labels and wavelengths in the dataset\n",
    "unique_labels = data[\"labels\"].unique()\n",
    "unique_wavelengths = data[\"wavelength\"].unique()\n",
    "\n",
    "unique_labels, unique_wavelengths\n",
    "\n",
    "# Create a figure to hold the adjusted plots\n",
    "fig, axes = plt.subplots(len(unique_labels), 2, figsize=(12, 24), sharex=False)\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "\n",
    "# Loop through each label and wavelength to create adjusted plots\n",
    "for i, label in enumerate(unique_labels):\n",
    "    for j, wavelength in enumerate(unique_wavelengths):\n",
    "        # Filter the data for the current label and wavelength\n",
    "        filtered_data = data[\n",
    "            (data[\"labels\"] == label) & (data[\"wavelength\"] == wavelength)\n",
    "        ]\n",
    "\n",
    "        # Plot value over time with adjusted x-axis\n",
    "        sns.lineplot(\n",
    "            ax=axes[i, j],\n",
    "            x=\"time_s\",\n",
    "            y=\"value\",\n",
    "            data=filtered_data,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "        # Set the title and labels\n",
    "        axes[i, j].set_title(f\"{label}, Wavelength: {wavelength}\")\n",
    "        axes[i, j].set_xlabel(\"Time (s)\")\n",
    "        axes[i, j].set_ylabel(\"Value\")\n",
    "\n",
    "        # Adjust the x-axis to show only the range with data\n",
    "        if not filtered_data.empty:\n",
    "            min_time = filtered_data[\"time_s\"].min()\n",
    "            max_time = filtered_data[\"time_s\"].max()\n",
    "            axes[i, j].set_xlim(min_time, max_time)\n",
    "\n",
    "# Adjust layout to make room for titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the adjusted plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P700 data over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def calculate_fvfm(data, pulse_start, pulse_end):\n",
    "    # Calculate Fv/Fm\n",
    "    # Fv = Fm - Fo\n",
    "    # Fm = max fluorescence\n",
    "    # Fo = minimal fluorescence\n",
    "    # Fv/Fm = (Fm - Fo) / Fm    # Fo is the minimal fluorescence measured in the dark-adapted state\n",
    "\n",
    "    # halfway through the pulse,\n",
    "    pulse_midpoint = pulse_start + ((pulse_end - pulse_start) // 2)\n",
    "    prepulse_midpoint = pulse_start // 2\n",
    "\n",
    "    # reindex the data\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    Fo = data.iloc[prepulse_midpoint : pulse_start - 5][\"value\"].mean()\n",
    "    Fm = data.iloc[pulse_midpoint : pulse_end - 5][\"value\"].mean()\n",
    "    FvFm = round((Fm - Fo) / Fm, 2)\n",
    "    print(f\"Fo: {Fo}, Fm: {Fm}, Fv/Fm: {FvFm}\")\n",
    "\n",
    "    return round((Fm - Fo) / Fm, 2)  # two decimal places is fine\n",
    "\n",
    "\n",
    "data_p700 = pd.read_csv(f\"output_data/{experiment_name}.csv\")\n",
    "true_zero = 0\n",
    "\n",
    "\n",
    "# Filter by wavelength\n",
    "data_fluor = data_p700[data_p700[\"wavelength\"] == \"530nm\"]\n",
    "data_p700 = data_p700[data_p700[\"wavelength\"] == \"820nm\"]\n",
    "\n",
    "# get the mean, max and min of the values\n",
    "p700_min, p700_max, p700_mean = data_p700[\"value\"].min(), data_p700[\"value\"].max(), data_p700[\"value\"].mean()\n",
    "\n",
    "# p700 min is the max of either the min value, or the mean * 0.99\n",
    "p700_min = min(p700_min - 100, p700_mean * 0.99)\n",
    "\n",
    "# p700 max is the min of either the max value, or the mean * 1.01\n",
    "p700_max = max(p700_max + 100, p700_mean * 1.01)\n",
    "\n",
    "print(f\"p700_min: {p700_min}, p700_max: {p700_max}\")\n",
    "\n",
    "# get unique trace labels\n",
    "sorted_labels = sorted(data_p700[\"labels\"].unique())\n",
    "unique_labels = []\n",
    "\n",
    "# we want the reference first, then pmax, then the rest in order of the numver after \"p700_\"\n",
    "# reference is last, so we pop it and insert it at the beginning\n",
    "unique_labels.insert(0, sorted_labels.pop())\n",
    "\n",
    "# now we want to pop the pmax and insert it at the beginning, after the reference\n",
    "unique_labels.insert(1, sorted_labels.pop())\n",
    "\n",
    "# now the first two are in the right order, but the others are not.\n",
    "# we want to sort the rest of the labels by the number after \"p700_\"\n",
    "sorted_labels = sorted(sorted_labels, key=lambda x: int(x.split(\"_\")[-1]))\n",
    "\n",
    "# now we want to insert the sorted labels into the unique_labels list, after the pmax\n",
    "for label in sorted_labels:\n",
    "    unique_labels.append(label)\n",
    "    \n",
    "print(unique_labels)\n",
    "\n",
    "# get fvfm from the fvfm trace, for the max value\n",
    "fvfm = calculate_fvfm(data_fluor[data_fluor[\"labels\"] == \"fvfm\"], 100, 150)\n",
    "\n",
    "# get the pmax, and calculate the maximum value during the pulse\n",
    "pmax = data_p700[data_p700[\"labels\"] == \"p700_PMAX\"]\n",
    "pmax = pmax.iloc[-150:140][\"value\"].mean()\n",
    "\n",
    "print(f\"pmax: {pmax}\")\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "fluor_data = {}\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    ax = plt.subplot(2, len(unique_labels), i + 1)\n",
    "\n",
    "    label_data = data_p700[data_p700[\"labels\"] == label]\n",
    "    label_data = label_data.iloc[10:]\n",
    "\n",
    "    if \"PMAX\" in label:\n",
    "        text_annotation = f\"Fv/Fm: {fvfm}\"\n",
    "        fluor_data[\"fvfm\"] = fvfm        \n",
    "    else:\n",
    "        phi2 = calculate_fvfm(data_fluor[data_fluor[\"labels\"] == label], 100, 150)\n",
    "        text_annotation = f\"Phi2: {phi2}\"\n",
    "        fluor_data[label.split(\"_\")[-1]] = phi2\n",
    "\n",
    "    sns.lineplot(x=\"time_s\", y=\"value\", data=label_data, linestyle=\"-\", linewidth=2)\n",
    "    ax.set_title(f\"P700 820nm {label}\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.text(\n",
    "        0.7,\n",
    "        0.4,\n",
    "        text_annotation,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=19,\n",
    "        verticalalignment=\"top\",\n",
    "    )\n",
    "    \n",
    "    ax.set_ylim(p700_min, p700_max)\n",
    "\n",
    "\n",
    "plt.suptitle(f\"{experiment_name} P700 820nm\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output_plots/{experiment_name}_820nm.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# export the fluor_data dict  as a dataframe and save to csv\n",
    "# the dict should be a column marked \"ue\" with the labels as the index, and the values as the values\n",
    "fluor_df = pd.DataFrame(fluor_data, index=[0])\n",
    "fluor_df.to_csv(f\"output_data/{experiment_name}_fluor.csv\")\n",
    "print(fluor_df.transpose().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the P700 values Pm, Pm', P, and P0\n",
    "calculate dAbs for the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calc_linear_regression(x: np.array, y: np.array) -> Tuple[float, float]:\n",
    "    # Create a DataFrame from the input arrays\n",
    "    df = pd.DataFrame({\"time_s\": x, \"dAbs\": y})\n",
    "\n",
    "    # Apply a rolling mean to the 'dAbs' column\n",
    "    window_size = 5\n",
    "    df[\"dAbs\"] = df[\"dAbs\"].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    lm = LinearRegression().fit(df[\"time_s\"].values.reshape(-1, 1), df[\"dAbs\"].values)\n",
    "\n",
    "    # Extract the slope and intercept\n",
    "    slope = lm.coef_[0]\n",
    "    intercept = lm.intercept_\n",
    "\n",
    "    return slope, intercept\n",
    "\n",
    "def calc_delta_absorbance(transmission: np.array, baseline_value: float) -> np.array:\n",
    "    \"\"\"Calculates delta absorbance for p700 data using a given baseline.\"\"\"\n",
    "    return (transmission / baseline_value) / (-1 / 2.3)\n",
    "\n",
    "# Function to calculate baseline for a specific label\n",
    "def calculate_baseline_for_label(data: pd.DataFrame, begin: int = -50, end: int = -1) -> float:\n",
    "    \"\"\"Calculates the baseline absorbance for a given label.\"\"\"\n",
    "    transmission = data[\"value\"].values\n",
    "    baseline_value = np.mean(transmission[begin:end])\n",
    "    return baseline_value\n",
    "\n",
    "def calculate_fvfm(data, pulse_start, pulse_end):\n",
    "    # halfway through the pulse,\n",
    "    pulse_midpoint = pulse_start + ((pulse_end - pulse_start) // 2)\n",
    "    prepulse_midpoint = pulse_start // 2\n",
    "\n",
    "    # reindex the data\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    Fo = data.iloc[prepulse_midpoint : pulse_start - 5][\"value\"].mean()\n",
    "    Fm = data.iloc[pulse_midpoint : pulse_end - 5][\"value\"].mean()\n",
    "    FvFm = round((Fm - Fo) / Fm, 2)\n",
    "\n",
    "    return round((Fm - Fo) / Fm, 2)  # two decimal places is fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the non-normalized data, and calculate the dAbs for each label\n",
    "data = pd.read_csv(f\"output_data/{experiment_name}.csv\")\n",
    "\n",
    "# remove all points  less than  10 time_ms_trace\n",
    "data = data[data[\"time_ms_trace\"] > 10]\n",
    "\n",
    "\n",
    "# check the true zero to see if we're going crazy\n",
    "true_zero = data[data[\"labels\"].str.contains(\"artifact\")][\"value\"][0:100].mean()\n",
    "\n",
    "# Filter by wavelength\n",
    "data_fluor = data[data[\"wavelength\"] == \"530nm\"]\n",
    "data_p700 = data[data[\"wavelength\"] == \"820nm\"]\n",
    "\n",
    "# pulse start at 500ms and ends at 750ms\n",
    "pulse_start = 500\n",
    "pulse_end = 750\n",
    "\n",
    "\n",
    "# Calculate dAbs for each label and save it in the DataFrame\n",
    "for label in unique_labels:\n",
    "    # Filter data for the current label\n",
    "    label_data = data_p700[data_p700[\"labels\"] == label].copy()\n",
    "\n",
    "    # Calculate baseline for the current label\n",
    "    baseline_value = calculate_baseline_for_label(\n",
    "        label_data, -20, -5\n",
    "    )\n",
    "\n",
    "    # Calculate dAbs for each row in the label_data\n",
    "    label_data[\"dAbs\"] = calc_delta_absorbance(\n",
    "        label_data[\"value\"].values, baseline_value\n",
    "    )\n",
    "\n",
    "    # Update the main DataFrame (data_p700) with the calculated dAbs values for the current label\n",
    "    data_p700.loc[data_p700[\"labels\"] == label, \"dAbs\"] = label_data[\"dAbs\"]\n",
    "\n",
    "data_p700.to_csv(f\"output_data/{experiment_name}_dAbs.csv\")\n",
    "\n",
    "# plot dAbs for 250\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "\n",
    "# get the mean, max and min of the values\n",
    "p700_min, p700_max = (\n",
    "    data_p700[\"dAbs\"].min() - 0.005,\n",
    "    data_p700[\"dAbs\"].max() + 0.005, \n",
    ")\n",
    "\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "\n",
    "    ax = plt.subplot(1, len(data_p700[\"labels\"].unique()), i + 1)\n",
    "    label_data = data_p700[data_p700[\"labels\"] == label].copy().reset_index(drop=True)\n",
    "\n",
    "    print(len(label_data))\n",
    "\n",
    "    # # set a vertical line\n",
    "    ax.axvline(pulse_start, color=\"red\", linestyle=\"--\")\n",
    "    ax.axvline(pulse_end, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    sns.lineplot(\n",
    "        x=\"time_ms_trace\", y=\"dAbs\", data=label_data, linestyle=\"-\", linewidth=2\n",
    "    )\n",
    "    ax.set_title(f\"{label}\", fontsize=16)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Abs\")\n",
    "    \n",
    "    ax.set_ylim(p700_min, p700_max)\n",
    "\n",
    "plt.suptitle(f\"{experiment_name} 820nm dAbs\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output_plots/{experiment_name}_820nm_dAbs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "pm_start, pm_end = 475, 600\n",
    "p_start, p_end = 250, 495\n",
    "po_start, po_end = 1150, 1250\n",
    "\n",
    "def get_p_vals(data: pd.DataFrame, x: str = \"time_ms_trace\", y: str = \"dAbs\") -> Tuple[float, float, float]:\n",
    "    # Create a mask for rows where \"time_ms_trace\" is between 500 and 750\n",
    "    pm_mask = (data[x] >= pm_start) & (data[x] <= pm_end)\n",
    "    p_mask = (data[x] >= p_start) & (data[x] <= p_end)\n",
    "    po_mask = (data[x] >= po_start) & (data[x] <= po_end)\n",
    "\n",
    "    # Use the masks to filter the \"ox_fraction\" column and calculate the max and mean values\n",
    "    Pmp = data.loc[pm_mask, y].max()\n",
    "    P = data.loc[p_mask, y].dropna().mean()\n",
    "    Po = data.loc[po_mask, y].mean()\n",
    "\n",
    "    return (Pmp, P, Po)\n",
    "\n",
    "data_p700 = pd.read_csv(f\"output_data/{experiment_name}_dAbs.csv\")\n",
    "\n",
    "# normalize the data using the values from the pmax trace\n",
    "pmax_df = data_p700[data_p700[\"labels\"].str.contains(\"p700_PMAX\")]\n",
    "\n",
    "# calculate p values\n",
    "Pm, P, Po = get_p_vals(pmax_df)\n",
    "print(f\"Pm: {Pm}, P: {P}, Po: {Po}\")\n",
    "\n",
    "data_p700[\"ox_fraction\"] = (data_p700[\"dAbs\"] - Po) / (Pm - Po)\n",
    "data_p700.to_csv(f\"output_data/{experiment_name}_dAbs_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the normalized data and plot it, with the P values shown as horizontal lines\n",
    "data_p700 = pd.read_csv(f\"output_data/{experiment_name}_dAbs_normalized.csv\")\n",
    "\n",
    "# only if the wavelength is 820nm\n",
    "data_p700 = data_p700[data_p700[\"wavelength\"] == \"820nm\"]\n",
    "\n",
    "\n",
    "# param locations in plot\n",
    "param_x = 900\n",
    "\n",
    "# list to save the P values\n",
    "p_vals = []\n",
    "\n",
    "# normalized data\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.suptitle(f\"{experiment_name} P700 Oxidation\", fontsize=20)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "\n",
    "    print(f\"label: {label}\")\n",
    "    if (\"reference\" in label):\n",
    "        continue\n",
    "\n",
    "    if \"PMAX\" in label:\n",
    "        title_label = f\"P700 @ {label}\"\n",
    "    else:\n",
    "        light_intensity = label.split(\"_\")[-1]\n",
    "        title_label = f\"P700 @ {light_intensity}ue\"\n",
    "\n",
    "    ax = plt.subplot(1, len(data_p700[\"labels\"].unique()), i + 1)\n",
    "    label_data = data_p700[data_p700[\"labels\"] == label]\n",
    "    label_data = label_data.iloc[10:]\n",
    "    label_data = label_data.reset_index(drop=True)\n",
    "\n",
    "    if \"PMAX\" not in label:\n",
    "        # calculate the Pmp, P, Po for all of the non-PMAX traces\n",
    "        Pmp, P, Po = get_p_vals(label_data, x=\"time_ms_trace\", y=\"ox_fraction\")\n",
    "        Pm = 1.0\n",
    "\n",
    "        print(f\"Pm: {Pm}, Pmp: {Pmp}, P: {P}, Po: {Po}\")\n",
    "        p_vals.append({\"ue\": light_intensity,\n",
    "                        \"Pm\": Pm,\n",
    "                        \"Pmp\": Pmp,\n",
    "                        \"P\": P,\n",
    "                        \"Po\": Po,\n",
    "                        \"Y(I)\": Pmp - P,\n",
    "                        \"Y(ND)\": P - Po,\n",
    "                        \"Y(NA)\": Pm - Pmp\n",
    "                        })\n",
    "\n",
    "    # plot the normalized data as lines, with points as well   \n",
    "    sns.lineplot(\n",
    "        x=\"time_ms_trace\",\n",
    "        y=\"ox_fraction\",\n",
    "        data=label_data,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        markersize=5,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # if the label is not PMAX, then plot these:\n",
    "    if \"PMAX\" not in label:\n",
    "        ax.hlines(Pm, 0, 1300, color=\"red\", linestyle=\"--\") # Pm\n",
    "        ax.hlines(Pmp, 0, 1300, color=\"green\", linestyle=\"--\") # Pm'\n",
    "        ax.hlines(P, 0, 1300, color=\"blue\", linestyle=\"--\") # P\n",
    "        ax.hlines(Po, 0, 1300, color=\"black\", linestyle=\"--\") # Po\n",
    "\n",
    "        # put a P next to the P line, a P' next to the P' line, etc\n",
    "        ax.text(0, Pm, \"Pm\", fontsize=14)\n",
    "        ax.text(0, Pmp, \"Pmp\", fontsize=14)\n",
    "        ax.text(0, P, \"P\", fontsize=14)\n",
    "        ax.text(0, Po, \"Po\", fontsize=14)\n",
    "    else:\n",
    "        ax.set_ylabel(\"Fraction of P700 oxidized\", fontsize=14)\n",
    "        ax.hlines(1, 0, 1300, color=\"red\", linestyle=\"--\")  # Everything is oxidized\n",
    "\n",
    "    # now we need to add text annotations for the Y() values onto the plot, for each trace\n",
    "    if \"PMAX\" not in label:\n",
    "        ax.text(param_x, Pm - 0.05, f\"Y(NA): {round(1 - Pmp, 2)}\",fontsize=14, horizontalalignment=\"left\")\n",
    "        ax.text(param_x, Pmp - 0.05, f\"Y(I): {round(Pmp - P, 2)}\",fontsize=14, horizontalalignment=\"left\")\n",
    "        ax.text(param_x, P - 0.05, f\"Y(ND): {round(P, 2)}\", fontsize=14, horizontalalignment=\"left\")\n",
    "    ax.set_ylim(-0.1, 1.1) # set the y-axis limits, so we can see how the data changes from the normalized value\n",
    "    ax.set_title(f\"{title_label}\", fontsize=14)\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output_plots/{experiment_name}_p700_oxidation_normalized.png\")\n",
    "plt.show()\n",
    "\n",
    "print(p_vals)\n",
    "\n",
    "# create a dataframe of the p_vals, save it\n",
    "p_vals_df = pd.DataFrame(p_vals)\n",
    "p_vals_df.to_csv(f\"output_data/{experiment_name}_p_vals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the normalized data and plot it, with the P values shown as horizontal lines\n",
    "data_p700 = pd.read_csv(f\"output_data/{experiment_name}_dAbs_normalized.csv\")\n",
    "\n",
    "# only if the wavelength is 820nm\n",
    "data_p700 = data_p700[data_p700[\"wavelength\"] == \"820nm\"]\n",
    "\n",
    "\n",
    "# param locations in plot\n",
    "param_x = 900\n",
    "\n",
    "# list to save the P values\n",
    "p_vals = []\n",
    "\n",
    "# normalized data\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.suptitle(f\"{experiment_name} P700 Oxidation\", fontsize=20)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "\n",
    "    print(f\"label: {label}\")\n",
    "    if (\"reference\" in label):\n",
    "        continue\n",
    "\n",
    "    if \"PMAX\" in label:\n",
    "        title_label = f\"P700 @ {label}\"\n",
    "    else:\n",
    "        light_intensity = label.split(\"_\")[-1]\n",
    "        title_label = f\"P700 @ {light_intensity}ue\"\n",
    "\n",
    "    ax = plt.subplot(1, len(data_p700[\"labels\"].unique()), i + 1)\n",
    "    label_data = data_p700[data_p700[\"labels\"] == label]\n",
    "    label_data = label_data.iloc[10:]\n",
    "    label_data = label_data.reset_index(drop=True)\n",
    "\n",
    "    if \"PMAX\" not in label:\n",
    "        # calculate the Pmp, P, Po for all of the non-PMAX traces\n",
    "        Pmp, P, Po = get_p_vals(label_data, x=\"time_ms_trace\", y=\"ox_fraction\")\n",
    "        Pm = 1.0\n",
    "\n",
    "        print(f\"Pm: {Pm}, Pmp: {Pmp}, P: {P}, Po: {Po}\")\n",
    "        p_vals.append({\"ue\": light_intensity,\n",
    "                        \"Pm\": Pm,\n",
    "                        \"Pmp\": Pmp,\n",
    "                        \"P\": P,\n",
    "                        \"Po\": Po,\n",
    "                        \"Y(I)\": Pmp - P,\n",
    "                        \"Y(ND)\": P - Po,\n",
    "                        \"Y(NA)\": Pm - Pmp\n",
    "                        })\n",
    "\n",
    "    # plot the normalized data as lines, with points as well   \n",
    "    sns.lineplot(\n",
    "        x=\"time_ms_trace\",\n",
    "        y=\"ox_fraction\",\n",
    "        data=label_data,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "        markersize=5,\n",
    "        marker=\"o\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(pm_start - 50, pm_end + 50)\n",
    "\n",
    "\n",
    "    # if the label is not PMAX, then plot these:\n",
    "    if \"PMAX\" not in label:\n",
    "        ax.hlines(Pm, 0, 1300, color=\"red\", linestyle=\"--\") # Pm\n",
    "        ax.hlines(Pmp, 0, 1300, color=\"green\", linestyle=\"--\") # Pm'\n",
    "        ax.hlines(P, 0, 1300, color=\"blue\", linestyle=\"--\") # P\n",
    "        ax.hlines(Po, 0, 1300, color=\"black\", linestyle=\"--\") # Po\n",
    "\n",
    "        # put a P next to the P line, a P' next to the P' line, etc\n",
    "        ax.text(0, Pm, \"Pm\", fontsize=14)\n",
    "        ax.text(0, Pmp, \"Pmp\", fontsize=14)\n",
    "        ax.text(0, P, \"P\", fontsize=14)\n",
    "        ax.text(0, Po, \"Po\", fontsize=14)\n",
    "    else:\n",
    "        ax.set_ylabel(\"Fraction of P700 oxidized\", fontsize=14)\n",
    "        ax.hlines(1, 0, 1300, color=\"red\", linestyle=\"--\")  # Everything is oxidized\n",
    "\n",
    "    # now we need to add text annotations for the Y() values onto the plot, for each trace\n",
    "    if \"PMAX\" not in label:\n",
    "        ax.text(param_x, Pm - 0.05, f\"Y(NA): {round(1 - Pmp, 2)}\",fontsize=14, horizontalalignment=\"left\")\n",
    "        ax.text(param_x, Pmp - 0.05, f\"Y(I): {round(Pmp - P, 2)}\",fontsize=14, horizontalalignment=\"left\")\n",
    "        ax.text(param_x, P - 0.05, f\"Y(ND): {round(P, 2)}\", fontsize=14, horizontalalignment=\"left\")\n",
    "    ax.set_ylim(-0.1, 1.1) # set the y-axis limits, so we can see how the data changes from the normalized value\n",
    "    ax.set_title(f\"{title_label}\", fontsize=14)\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output_plots/{experiment_name}_p700_oxidation_normalized_zoom.png\")\n",
    "plt.show()\n",
    "\n",
    "print(p_vals)\n",
    "\n",
    "# create a dataframe of the p_vals, save it\n",
    "p_vals_df = pd.DataFrame(p_vals)\n",
    "p_vals_df.to_csv(f\"output_data/{experiment_name}_p_vals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "Calculate p' whichever is higher, last few datapoints of p or a mean of the first few datapoints during the pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjust the pmax calculation\n",
    "\n",
    "Either take the mean of the first few points of the pulse, or the mean of the last few points of the prepulse, whichever is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the p_vals dataframe\n",
    "p_vals_df = pd.read_csv(f\"output_data/{experiment_name}_p_vals.csv\")\n",
    "p_vals_df = p_vals_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# load the fluor data as well\n",
    "fluor_df = pd.read_csv(f\"output_data/{experiment_name}_fluor.csv\")\n",
    "fluor_df = fluor_df.drop(columns=[\"Unnamed: 0\"]).transpose()\n",
    "\n",
    "# drop all rows that have label including \"reference\"\n",
    "fluor_df = fluor_df[~fluor_df.index.str.contains(\"reference\")]\n",
    "\n",
    "# index to column\n",
    "fluor_df = fluor_df.reset_index()\n",
    "\n",
    "# rename the columns\n",
    "fluor_df.columns = [\"ue\", \"value\"]\n",
    "\n",
    "# extract the fvfm value for later use\n",
    "fvfm = fluor_df[fluor_df[\"ue\"] == \"fvfm\"][\"value\"].values[0]\n",
    "\n",
    "# slice teh dataframe to get all ue that are not fvfm\n",
    "fluor_df = fluor_df[fluor_df[\"ue\"] != \"fvfm\"]\n",
    "\n",
    "# convert the ue column to int64\n",
    "fluor_df[\"ue\"] = fluor_df[\"ue\"].astype(\"int64\").copy()\n",
    "\n",
    "# value is now the Phi2 value\n",
    "p_vals_df[\"PhiII\"] = fluor_df[\"value\"].values\n",
    "p_vals_df[\"FvFm\"] = fvfm\n",
    "p_vals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot Phi2 vs Y(I)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "# plot the Phi2 vs Y(I)\n",
    "sns.scatterplot(x=\"PhiII\", y=\"Y(I)\", data=p_vals_df, s=100, color=\"blue\")\n",
    "\n",
    "# add a title and labels\n",
    "plt.suptitle(f\"{experiment_name}\", fontsize=18)\n",
    "plt.title(f\"Phi2 vs Y(I)\", fontsize=18)\n",
    "\n",
    "# add labels\n",
    "plt.xlabel(\"Phi2\", fontsize=20)\n",
    "plt.ylabel(\"Y(I)\", fontsize=20)\n",
    "\n",
    "plt.savefig(f\"output_plots/{experiment_name}_Phi2_vs_YI.png\")\n",
    "plt.show()\n",
    "p_vals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for the p700 traces\n",
    "params = {}\n",
    "\n",
    "# calc pmax first\n",
    "pmax_df = data_p700[data_p700[\"labels\"] == \"p700_PMAX\"]\n",
    "params[\"Pm\"] = pmax_df[\"dAbs\"].iloc[-150:-140].mean()\n",
    "params[\"Po\"] = pmax_df[\"dAbs\"].iloc[-20:].mean()\n",
    "\n",
    "for label in data_p700[\"labels\"].unique():\n",
    "\n",
    "    if \"PMAX\" not in label and \"refer\" not in label:\n",
    "        print(f\"label: {label}\")\n",
    "        df = data_p700[data_p700[\"labels\"] == label]\n",
    "\n",
    "        params[label] = {\n",
    "            \"phi2\": calculate_fvfm(data_fluor[data_fluor[\"labels\"] == label], 100, 150),\n",
    "            \"P\": df[\"dAbs\"].iloc[-170:-150].mean(),\n",
    "            \"Pmp\": df[\"dAbs\"].iloc[-150:-140].mean(),\n",
    "            \"Po\": df[\"dAbs\"].iloc[-20:].mean(),\n",
    "        }\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_y_axis(ax):\n",
    "    # Remove tick marks and labels from the y-axis\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the time series of the Fluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def calculate_fvfm(data, pulse_start, pulse_end):\n",
    "    # Calculate Fv/Fm\n",
    "    # Fv = Fm - Fo\n",
    "    # Fm = max fluorescence\n",
    "    # Fo = minimal fluorescence\n",
    "    # Fv/Fm = (Fm - Fo) / Fm    # Fo is the minimal fluorescence measured in the dark-adapted state\n",
    "\n",
    "    # halfway through the pulse,\n",
    "    pulse_midpoint = pulse_start + ((pulse_end - pulse_start) // 2)\n",
    "    prepulse_midpoint = pulse_start // 2\n",
    "\n",
    "    # reindex the data\n",
    "    data = data.copy().reset_index(drop=True)\n",
    "\n",
    "    Fo = data.iloc[pulse_start -5 : pulse_start][\"value\"].mean()\n",
    "    Fm = data.iloc[pulse_midpoint : pulse_end - 5][\"value\"].mean()\n",
    "    FvFm = round((Fm - Fo) / Fm, 2)\n",
    "    print(f\"Fo: {Fo}, Fm: {Fm}, Fv/Fm: {FvFm}\")\n",
    "\n",
    "    return round((Fm - Fo) / Fm, 2)  # two decimal places is fine\n",
    "\n",
    "\n",
    "data_csv_fluor_2 = pd.read_csv(f\"output_data/{experiment_name}.csv\")\n",
    "\n",
    "# Filter by wavelength\n",
    "data_green = data_csv_fluor_2[data_csv_fluor_2[\"wavelength\"] == \"530nm\"]\n",
    "\n",
    "\n",
    "# sort for the order of the traces\n",
    "sorted_labels = sorted(data_green[\"labels\"].unique())\n",
    "\n",
    "sorted_labels = [\n",
    "    label\n",
    "    for label in sorted_labels\n",
    "    if (\"fvfm\" in label or \"p700\" in label or \"fluor\" in label) and (\"PMAX\" not in label)\n",
    "]\n",
    "\n",
    "unique_labels = []\n",
    "light_labels = []\n",
    "\n",
    "for label in sorted_labels:\n",
    "    if \"p700\" in label:\n",
    "        light_labels.append(label)\n",
    "    else:\n",
    "        unique_labels.append(label)\n",
    "\n",
    "sorted_labels = sorted(light_labels, key=lambda x: int(x.split(\"_\")[-1]))\n",
    "\n",
    "unique_labels.extend(sorted_labels)\n",
    "\n",
    "print(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels_green = unique_labels\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "# get the ylim values for the fvfm trace, by finding the max value for the \"value\" column where the label == \"fvfm\"\n",
    "label_data = data_green[data_green[\"labels\"] == \"fvfm\"]\n",
    "ylim = [0, np.max(label_data[\"value\"]) * 1.1]\n",
    "\n",
    "# Plot green data\n",
    "for i, label in enumerate(unique_labels_green):\n",
    "    \n",
    "\n",
    "    ax = plt.subplot(2, len(unique_labels_green), i + 1)\n",
    "    label_data = data_green[data_green[\"labels\"] == label]\n",
    "    fvfm = calculate_fvfm(label_data, 100, 150)\n",
    "    sns.lineplot(x=\"time_s\", y=\"value\", data=label_data, linestyle=\"-\", linewidth=2)\n",
    "    ax.set_title(f\"Fluor {label} (Fv/Fm: {fvfm})\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    \n",
    "\n",
    "    # else:\n",
    "    #     remove_y_axis(ax)\n",
    "        \n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    \n",
    "    # Add Fv/Fm text annotation within the plot\n",
    "    ax.text(\n",
    "        0.6,\n",
    "        0.9,\n",
    "        f\"Fv/Fm: {fvfm}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=12,\n",
    "        verticalalignment=\"top\",\n",
    "    )\n",
    "\n",
    "plt.suptitle(f\"{experiment_name} Fluor\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"output_plots/{experiment_name}_fluor.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
